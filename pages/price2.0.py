import streamlit as st
import pandas as pd
import re
from sqlalchemy import create_engine, text
from pathlib import Path
from collections import Counter

# â€” é¡µé¢é…ç½®ï¼šå®½å±å¸ƒå±€ã€æ ‡é¢˜ â€”
st.set_page_config(
    page_title="äº§å“æŠ¥ä»·ç³»ç»Ÿ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# â€” è‡ªå®šä¹‰ CSS â€”
st.markdown("""
<style>
/* ä¸»å®¹å™¨å¡ç‰‡ï¼Œæœ€å¤§å®½åº¦æ›´å¤§ */
.block-container {
    max-width: 1000px !important;
    margin: 2rem auto !important;
    background: #fff !important;
    padding: 2rem !important;
    border-radius: 10px !important;
    box-shadow: 0 4px 12px rgba(0,0,0,0.05) !important;
}
/* æ ‡é¢˜é¢œè‰² */
h1, h2 {
    color: #333 !important;
}
/* æŒ‰é’®ç¾åŒ– */
.stButton>button {
    background-color: #005B96 !important;
    color: #fff !important;
    border: none !important;
    border-radius: 5px !important;
    padding: 0.5em 1.5em !important;
    box-shadow: 0 2px 6px rgba(0,0,0,0.1) !important;
}
.stButton>button:hover {
    background-color: #004173 !important;
}
</style>
""", unsafe_allow_html=True)

# â€” é€šç”¨è®¾ç½® & æ•°æ®åº“è¿æ¥ â€”
DB_PATH = Path(__file__).resolve().parents[1] / "Product1.db"
engine = create_engine(f"sqlite:///{DB_PATH}", connect_args={"timeout":20}, echo=False)

@st.cache_data
def load_data():
    return pd.read_sql("SELECT * FROM Products", engine)


def normalize_material(s: str) -> str:
    s = s.lower()
    s = s.replace('ï¼', '-').replace('â€”', '-').replace('â€“', '-')
    s = re.sub(r'[\s_]', '', s)
    s = s.replace('ï¼ˆ', '(').replace('ï¼‰', ')')
    s = ''.join([chr(ord(c)-65248) if 65281 <= ord(c) <= 65374 else c for c in s])
    # æè´¨å½’ä¸€åŒ–
    s = re.sub(r'pp[\s\-_â€”â€“]?[rï½’r]', 'ppr', s)  # å½’ä¸€åŒ–pp-rã€pp rã€pp_rã€ppâ€”rã€ppâ€“rã€ppï½’ä¸ºppr
    s = s.replace('pvcu', 'pvc')
    s = s.replace('pvc-u', 'pvc')
    s = s.replace('pvc u', 'pvc')
    # åªæŠŠå¸¸è§åˆ†éš”ç¬¦æ›¿æ¢æˆç©ºæ ¼ï¼Œä¿ç•™*å·
    s = re.sub(r'[\|,;ï¼Œï¼›]', ' ', s)
    s = re.sub(r'\s+', ' ', s)
    if "å¼‚å¾„ä¸‰é€š" in s:
        print("å½’ä¸€åŒ–åæè¿°ï¼š", s)
    return s.strip()

def insert_product(values: dict):
    values.pop("åºå·", None)
    cols   = ", ".join(values.keys())
    params = ", ".join(f":{k}" for k in values)
    sql    = text(f"INSERT INTO Products ({cols}) VALUES ({params})")
    with engine.begin() as conn:
        conn.execute(sql, values)

def delete_products(materials: list[str]):
    if not materials:
        return
    with engine.begin() as conn:
        for m in materials:
            conn.execute(text("DELETE FROM Products WHERE Material = :m"), {"m": m})

# â€” åŒä¹‰è¯ & å•ä½æ˜ å°„å·¥å…· â€”
SYNONYM_GROUPS = [
    {"ç›´æ¥", "ç›´æ¥å¤´", "ç›´é€š"},
    {"å¤§å°å¤´", "å¼‚å¾„ç›´é€š", "å¼‚å¾„å¥—"},
    {"æ‰«é™¤å£", "æ¸…æ‰«å£"}
]

mm_to_inch = {"20": '1/2"', "25": '3/4"',
              "32": '1"', "50": '1-1/2"',
              "63": '2"', "75": '2-1/2"',
              "90": '3"', "110": '4"'}
inch_to_mm = {v:k for k,v in mm_to_inch.items()}

def get_synonym_words(word):
    for group in SYNONYM_GROUPS:
        if word in group:
            return group
    return {word}

def expand_unit_tokens(token):
    eqs = {token}
    # æ”¯æŒdnå‰ç¼€
    if token.startswith('dn'):
        num = token[2:]
        if num in mm_to_inch:
            eqs.add(mm_to_inch[num])
            # ä¹Ÿå¯ä»¥åŠ  'dn'+è‹±å¯¸
            eqs.add('dn' + mm_to_inch[num])
            if num in inch_to_mm:
                eqs.add('dn' + inch_to_mm[num])
    else:
        if token in mm_to_inch:
            eqs.add(mm_to_inch[token])
        if token in inch_to_mm:
            eqs.add(inch_to_mm[token])
    return eqs

def expand_token_with_synonyms_and_units(token):
    # å…ˆæŸ¥åŒä¹‰è¯ç»„
    synonyms = get_synonym_words(token)
    expanded = set()
    for syn in synonyms:
        expanded |= expand_unit_tokens(syn)
    return expanded
    
def split_with_synonyms(text):
    text = text.lower()
    tokens = []
    # å…ˆæå– dn+æ•°å­—*æ•°å­—
    pattern_dn = re.compile(r'dn\d+\*\d+')
    for m in pattern_dn.finditer(text):
        tokens.append(m.group())
    text = pattern_dn.sub(' ', text)
    # å†æå– æ•°å­—*æ•°å­—
    pattern_num = re.compile(r'\d+\*\d+')
    for m in pattern_num.finditer(text):
        tokens.append(m.group())
    text = pattern_num.sub(' ', text)
    # å†æå–è¿ç»­è‹±æ–‡/æ‹¼éŸ³
    pattern_en = re.compile(r'[a-zA-Z]+')
    for m in pattern_en.finditer(text):
        tokens.append(m.group())
    text = pattern_en.sub(' ', text)
    # å†æå–å•ä¸ªæ•°å­—
    pattern_digit = re.compile(r'\d+')
    for m in pattern_digit.finditer(text):
        tokens.append(m.group())
    text = pattern_digit.sub(' ', text)
    # å‰©ä¸‹çš„æŒ‰å•å­—åˆ‡åˆ†
    tokens += [c for c in text if c.strip()]
    return tokens

def classify_tokens(keyword):
    norm_kw = normalize_material(keyword)
    # æè´¨
    material_tokens = re.findall(r'pvc|ppr|pe|pp|hdpe|pb|pert', norm_kw)
    # æ•°å­—
    digit_tokens = re.findall(r'\d', norm_kw)
    # ä¸­æ–‡åŒä¹‰è¯æ•´ä½“åˆ‡åˆ†
    chinese_tokens = split_with_synonyms(keyword)
    return material_tokens, digit_tokens, chinese_tokens

def search_with_keywords(df, keyword, field, strict=True, return_score=False):
    material_tokens, digit_tokens, chinese_tokens = classify_tokens(keyword.strip())
    digit_counter = Counter(digit_tokens)
    results = []
    for row in df.itertuples(index=False):
        text = normalize_material(str(getattr(row, field, "")))
        # æè´¨å¿…é¡»å…¨éƒ¨å‘½ä¸­
        if not all(m in text for m in material_tokens):
            continue
        text_digit_counter = Counter(re.findall(r'\d', text))
        if not strict:
            # æ¨¡ç³ŠæŸ¥è¯¢æ—¶ï¼Œè¦æ±‚æ•°å­—å‡ºç°å’Œæ¬¡æ•°ä¸è¾“å…¥ä¸€è‡´
            if digit_counter and text_digit_counter != digit_counter:
                continue
        # ä¸­æ–‡éƒ¨åˆ†ï¼ˆåŒä¹‰è¯æ‰©å±•ï¼‰
        hit_count = 0
        if strict:
            if not all(any(syn in text for syn in expand_token_with_synonyms_and_units(c)) for c in chinese_tokens):
                continue
            hit_count = len(chinese_tokens)
        else:
            hit_count = sum(1 for c in chinese_tokens if any(syn in text for syn in expand_token_with_synonyms_and_units(c)))
            if chinese_tokens and hit_count == 0:
                continue
        if return_score:
            score = hit_count / len(chinese_tokens) if chinese_tokens else 1
            results.append((row, score))
        else:
            results.append(row)
    return results

# â€” Session State åˆå§‹åŒ– â€”
for k, default in [("cart",[]),("last_out",pd.DataFrame()),("to_cart",[]),("to_remove",[])]:
    if k not in st.session_state:
        st.session_state[k] = default

def add_to_cart():
    for i in st.session_state.to_cart:
        st.session_state.cart.append(st.session_state.last_out.loc[i].to_dict())
    # æ¸…ç©ºé€‰æ‹©ï¼ˆæ¨èç”¨ pop æˆ– delï¼‰
    if "to_cart" in st.session_state:
        del st.session_state["to_cart"]

def remove_from_cart():
    idxs = set(st.session_state.to_remove)
    st.session_state.cart = [it for j,it in enumerate(st.session_state.cart) if j not in idxs]
    if "to_remove" in st.session_state:
        del st.session_state["to_remove"]

# â€” ä¾§è¾¹æ å¯¼èˆª â€”
st.sidebar.header("å¯¼  èˆª")
page = st.sidebar.radio("æ“ä½œ", ["æŸ¥è¯¢äº§å“","æ·»åŠ äº§å“","åˆ é™¤äº§å“"])
st.sidebar.markdown("---")
st.sidebar.caption("Powered by Streamlit")


# é¡µé¢åˆ‡æ¢å’Œä¸»é€»è¾‘
if page == "æŸ¥è¯¢äº§å“":
    st.header("äº§å“æŸ¥è¯¢ç³»ç»Ÿ")
    df = load_data()

    
    c1, c3 = st.columns([6,1])
    with c1:
        keyword = st.text_input(
            "å…³é”®è¯ï¼ˆåç§°ã€è§„æ ¼ã€æè´¨å¯ä¸€èµ·è¾“å…¥ï¼‰",
            key="keyword"
        )
    with c3:
        qty = st.number_input(
            "æ•°é‡", min_value=1, key="qty"
        )
    mat_kw = st.text_input(
        "ç‰©æ–™å·æœç´¢", key="mat_kw"
    )
    price_type = st.selectbox(
        "ä»·æ ¼å­—æ®µ", ["å‡ºå‚ä»·_å«ç¨","å‡ºå‚ä»·_ä¸å«ç¨"],
        key="price_type"
    )
    fuzzy_mode = st.checkbox(
        "æœªæŸ¥åˆ°ç»“æœæ—¶å¯ç”¨æ¨¡ç³ŠæŸ¥æ‰¾ï¼ˆå¹¶æ˜¾ç¤ºåŒ¹é…åº¦ï¼‰",
        key="fuzzy_mode"
    )

    if st.button("æŸ¥è¯¢"):
        out_df = pd.DataFrame()
        qty = st.session_state.qty if "qty" in st.session_state else 1
        show_cols = ["Material", "Describrition", "æ•°é‡", "å‡ºå‚ä»·_å«ç¨", "å‡ºå‚ä»·_ä¸å«ç¨"]

        # ä¼˜å…ˆç‰©æ–™å·ç²¾ç¡®æŸ¥æ‰¾
        mat_kw = st.session_state.get("mat_kw", "").strip()
        if mat_kw:
            filtered = df[df["Material"].astype(str).str.contains(mat_kw)]
            if not filtered.empty:
                out_df = pd.DataFrame(filtered.copy())  # å¼ºåˆ¶DataFrame
                out_df["æ•°é‡"] = qty
                out_df = out_df[[col for col in show_cols if col in out_df.columns]]
                st.session_state.last_out = out_df
            else:
                st.session_state.last_out = pd.DataFrame()
                st.warning("âš ï¸ æœªæŸ¥è¯¢åˆ°ç¬¦åˆæ¡ä»¶çš„äº§å“")
        else:
            # åŸæœ‰å…³é”®è¯æŸ¥æ‰¾é€»è¾‘
            results = search_with_keywords(df, st.session_state.keyword, "Describrition", strict=True)
            if not results and st.session_state.fuzzy_mode:
                fuzzy_results = search_with_keywords(df, st.session_state.keyword, "Describrition", strict=False, return_score=True)
                if fuzzy_results:
                    out_df = pd.DataFrame([r[0] for r in fuzzy_results])
                    out_df["åŒ¹é…åº¦"] = [round(r[1], 2) for r in fuzzy_results]
                    out_df = out_df.sort_values("åŒ¹é…åº¦", ascending=False)
                    out_df["æ•°é‡"] = qty
                    show_cols_fuzzy = show_cols + ["åŒ¹é…åº¦"]
                    out_df = out_df[[col for col in show_cols_fuzzy if col in out_df.columns]]
                    st.session_state.last_out = out_df
                else:
                    st.session_state.last_out = pd.DataFrame()
                    st.warning("âš ï¸ æœªæŸ¥è¯¢åˆ°ç¬¦åˆæ¡ä»¶çš„äº§å“")
            elif results:
                out_df = pd.DataFrame(results)
                out_df["æ•°é‡"] = qty
                out_df = out_df[[col for col in show_cols if col in out_df.columns]]
                st.session_state.last_out = out_df
            else:
                st.session_state.last_out = pd.DataFrame()
                st.warning("âš ï¸ æœªæŸ¥è¯¢åˆ°ç¬¦åˆæ¡ä»¶çš„äº§å“")

    # æŸ¥è¯¢ç»“æœå±•ç¤ºå’Œè´­ç‰©è½¦æ“ä½œï¼ˆæ— è®ºæ˜¯å¦åˆšç‚¹äº†æŸ¥è¯¢æŒ‰é’®ï¼Œåªè¦æœ‰ç»“æœéƒ½æ˜¾ç¤ºï¼‰
    out_df = st.session_state.get("last_out", pd.DataFrame())
    if not out_df.empty and isinstance(out_df, pd.DataFrame):
        st.dataframe(out_df, use_container_width=True)
        def format_row(i):
            try:
                row = out_df.loc[i]
                if "äº§å“æè¿°" in out_df.columns:
                    return row["äº§å“æè¿°"]
                elif "Describrition" in out_df.columns:
                    return row["Describrition"]
                elif "Material" in out_df.columns:
                    return str(row["Material"])
                else:
                    return str(i)
            except Exception:
                return str(i)
        to_cart = st.multiselect(
            "é€‰æ‹©è¦åŠ å…¥è´­ç‰©è½¦çš„è¡Œ",
            options=list(out_df.index),
            format_func=format_row,
            key="to_cart"
        )
        if st.button("æ·»åŠ åˆ°è´­ç‰©è½¦", key="add_cart"):
            for i in to_cart:
                st.session_state.cart.append(out_df.loc[i].to_dict())
            if "to_cart" in st.session_state:
                del st.session_state["to_cart"]
            st.success("âœ… å·²åŠ å…¥è´­ç‰©è½¦")

    # è´­ç‰©è½¦åªåœ¨æœ‰å†…å®¹æ—¶æ˜¾ç¤º
    if st.session_state.cart:
        cart_df = pd.DataFrame(st.session_state.cart)
        st.dataframe(cart_df, use_container_width=True)
        to_remove = st.multiselect(
            "é€‰æ‹©è¦åˆ é™¤çš„è´­ç‰©è½¦æ¡ç›®",
            options=list(cart_df.index),
            format_func=lambda i: cart_df.loc[i, "äº§å“æè¿°"] if "äº§å“æè¿°" in cart_df.columns else cart_df.loc[i, "Describrition"],
            key="to_remove"
        )
        if st.button("åˆ é™¤æ‰€é€‰", key="del_cart_bottom"):
            idxs = set(to_remove)
            st.session_state.cart = [it for j, it in enumerate(st.session_state.cart) if j not in idxs]
            if "to_remove" in st.session_state:
                del st.session_state["to_remove"]
            st.rerun()

elif page == "æ·»åŠ äº§å“":
    st.header(" æ·»åŠ æ–°äº§å“åˆ°æ•°æ®åº“")
    df0 = load_data()
    cols = df0.columns.tolist()

    with st.form("add_form"):
        new_vals = {}
        for col in cols:
            if col == "åºå·":
                continue
            label = col + ("ï¼ˆå¿…å¡«ï¼‰" if col in ["Describrition","å‡ºå‚ä»·_å«ç¨","å‡ºå‚ä»·_ä¸å«ç¨"] else "")
            dtype = df0[col].dtype
            if col in ["å‡ºå‚ä»·_å«ç¨","å‡ºå‚ä»·_ä¸å«ç¨"]:
                new_vals[col] = st.text_input(label, key=f"add_{col}")
            elif pd.api.types.is_integer_dtype(dtype):
                new_vals[col] = st.number_input(label, step=1, format="%d", key=f"add_{col}")
            elif pd.api.types.is_float_dtype(dtype):
                new_vals[col] = st.number_input(label, format="%.2f", key=f"add_{col}")
            else:
                new_vals[col] = st.text_input(label, key=f"add_{col}")

        submitted = st.form_submit_button("æäº¤æ–°å¢")

    if submitted:
        missing = [
            f for f in ["Describrition","å‡ºå‚ä»·_å«ç¨","å‡ºå‚ä»·_ä¸å«ç¨"]
            if not new_vals.get(f) or (isinstance(new_vals[f], str) and not new_vals[f].strip())
        ]
        if missing:
            st.error(f"âš ï¸ ä»¥ä¸‹å­—æ®µä¸ºå¿…å¡«ï¼š{', '.join(missing)}")
        else:
            insert_product(new_vals)
            load_data.clear()
            st.success("âœ… äº§å“å·²æ·»åŠ åˆ°æ•°æ®åº“ï¼")

else:
    st.header("ğŸ—‘ï¸ åˆ é™¤äº§å“")
    df = load_data()
    if df.empty:
        st.info("å½“å‰æ— äº§å“å¯åˆ é™¤ã€‚")
    else:
        materials = st.multiselect(
            "è¯·é€‰æ‹©è¦åˆ é™¤çš„äº§å“ (Material)",
            options=df["Material"].tolist(),
            format_func=lambda m: str(m)
        )
        if st.button("åˆ é™¤é€‰ä¸­äº§å“"):
            delete_products(materials)
            load_data.clear()
            st.success("âœ… åˆ é™¤æˆåŠŸï¼")


